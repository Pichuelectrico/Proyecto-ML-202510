{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 2: Aprendizaje Semisupervisado para Clasificación de Rating\n",
        "\n",
        "Este notebook implementa un protocolo de aprendizaje semisupervisado utilizando el dataset procesado, con baseline supervisado, Self-Training y Label Spreading/Propagation (k-NN). Incluye EDA, configuración experimental, evaluación con métricas solicitadas y análisis de hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9235f055",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalación de dependencias necesarias (ejecutar una vez)\n",
        "import sys, subprocess\n",
        "packages = [\n",
        "    'numpy',\n",
        "    'pandas',\n",
        "    'matplotlib',\n",
        "    'seaborn',\n",
        "    'scikit-learn',\n",
        "    'scipy'\n",
        "]\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + packages)\n",
        "print('Instalación de dependencias completada')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuración general\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (f1_score, balanced_accuracy_score, confusion_matrix,\n",
        "                             roc_curve, auc)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier, LabelSpreading, LabelPropagation\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "DATA_PATH = os.path.join('..', 'data', 'processed', 'dataset.csv')\n",
        "assert os.path.exists(DATA_PATH), f'No se encuentra el dataset en {DATA_PATH}'\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estructura de datos y selección de variables\n",
        "- Las columnas de identificación `cooperativa` y `abreviacion` no se usan como features.\n",
        "- La columna de label es `Label`.\n",
        "- Se asume que los demás campos numéricos están preprocesados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición de columnas y división X / y\n",
        "id_cols = ['cooperativa', 'abreviacion']\n",
        "label_col = 'Label'\n",
        "assert label_col in df.columns, 'No se encontró la columna de label esperada'\n",
        "feature_cols = [c for c in df.columns if c not in id_cols + [label_col]]\n",
        "X = df[feature_cols].copy()\n",
        "y = df[label_col].astype(str).copy()\n",
        "classes_ = np.unique(y)\n",
        "n_classes = len(classes_)\n",
        "X.shape, y.value_counts().to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EDA: Distribuciones, correlaciones y t-SNE\n",
        "Exploramos la distribución de indicadores, correlaciones y redundancias, y visualizamos con t-SNE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribución de indicadores (histogramas)\n",
        "_ = X.hist(figsize=(16, 12), bins=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Matriz de correlación\n",
        "plt.figure(figsize=(12,10))\n",
        "corr = X.corr(numeric_only=True)\n",
        "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
        "plt.title('Matriz de correlación')\n",
        "plt.show()\n",
        "\n",
        "# Redundancias: pares con |corr| > 0.9\n",
        "high_corr = []\n",
        "thr = 0.9\n",
        "for i, c1 in enumerate(feature_cols):\n",
        "    for j, c2 in enumerate(feature_cols):\n",
        "        if j <= i:\n",
        "            continue\n",
        "        val = corr.loc[c1, c2]\n",
        "        if abs(val) > thr:\n",
        "            high_corr.append((c1, c2, float(val)))\n",
        "pd.DataFrame(high_corr, columns=['feat1','feat2','corr']).sort_values('corr', key=lambda s: s.abs(), ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# t-SNE para visualización\n",
        "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=int(np.clip(len(X)//5, 5, 30)))\n",
        "emb = tsne.fit_transform(X)\n",
        "emb_df = pd.DataFrame(emb, columns=['tsne1','tsne2'])\n",
        "emb_df[label_col] = y.values\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=emb_df, x='tsne1', y='tsne2', hue=label_col, palette='tab10')\n",
        "plt.title('t-SNE de indicadores (color=Label)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Configuración y protocolo\n",
        "- `p ∈ {5%, 10%, 20%, 40%, 60%, 80%}` como fracción etiquetada en Train.\n",
        "- 10 repeticiones por `p`.\n",
        "- Preprocesamiento: imputación, escalado y filtro de varianza.\n",
        "- Semilla fija para reproducibilidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline de preprocesamiento y utilidades\n",
        "preprocess = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('varth', VarianceThreshold(threshold=0.0))\n",
        "])\n",
        "\n",
        "def make_rf(random_state=RANDOM_STATE):\n",
        "    return RandomForestClassifier(n_estimators=400, max_depth=None, n_jobs=-1, random_state=random_state)\n",
        "\n",
        "def compute_metrics(y_true, y_pred, labels):\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro', labels=labels)\n",
        "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    return f1_macro, bal_acc, cm\n",
        "\n",
        "def compute_roc_auc(y_true, proba, classes):\n",
        "    y_bin = label_binarize(y_true, classes=classes)\n",
        "    fpr = {}; tpr = {}; roc_auc = {}\n",
        "    for i, c in enumerate(classes):\n",
        "        fpr[c], tpr[c], _ = roc_curve(y_bin[:, i], proba[:, i])\n",
        "        from numpy import trapz\n",
        "        roc_auc[c] = np.trapz(tpr[c], fpr[c])\n",
        "    all_fpr = np.unique(np.concatenate([fpr[c] for c in classes]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for c in classes:\n",
        "        mean_tpr += np.interp(all_fpr, fpr[c], tpr[c])\n",
        "    mean_tpr /= len(classes)\n",
        "    macro_auc = np.trapz(mean_tpr, all_fpr)\n",
        "    return roc_auc, macro_auc, fpr, tpr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Modelos: Baseline y Semisupervisados\n",
        "- Baseline: Random Forest entrenado solo con la porción etiquetada.\n",
        "- Self-Training: RF base con umbral de confianza `τ`.\n",
        "- Label Spreading/Propagation: kernel `knn` con `k` vecinos (distancia euclidiana tras escalado)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def fit_predict_baseline(X_l, y_l, X_te):\n",
        "    pipe = Pipeline(steps=[('prep', preprocess), ('clf', make_rf())])\n",
        "    pipe.fit(X_l, y_l)\n",
        "    y_pred = pipe.predict(X_te)\n",
        "    proba = pipe.predict_proba(X_te) if hasattr(pipe.named_steps['clf'], 'predict_proba') else None\n",
        "    return y_pred, proba, pipe\n",
        "\n",
        "def fit_predict_self_training(X_tr, y_tr_with_unlabeled, X_te, threshold):\n",
        "    base = make_rf()\n",
        "    st = SelfTrainingClassifier(base_estimator=base, threshold=threshold, verbose=False)\n",
        "    pipe = Pipeline(steps=[('prep', preprocess), ('clf', st)])\n",
        "    pipe.fit(X_tr, y_tr_with_unlabeled)\n",
        "    y_pred = pipe.predict(X_te)\n",
        "    proba = None\n",
        "    try:\n",
        "        proba = pipe.predict_proba(X_te)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return y_pred, proba, pipe\n",
        "\n",
        "def fit_predict_label_graph(X_tr, y_tr_with_unlabeled, X_te, method='spreading', k=10):\n",
        "    if method == 'spreading':\n",
        "        lg = LabelSpreading(kernel='knn', n_neighbors=int(k), alpha=0.2)\n",
        "    else:\n",
        "        lg = LabelPropagation(kernel='knn', n_neighbors=int(k))\n",
        "    scaler = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
        "    X_tr_s = scaler.fit_transform(X_tr)\n",
        "    lg.fit(X_tr_s, y_tr_with_unlabeled)\n",
        "    X_te_s = scaler.transform(X_te)\n",
        "    y_pred = lg.predict(X_te_s)\n",
        "    proba = None\n",
        "    try:\n",
        "        proba = lg.predict_proba(X_te_s)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return y_pred, proba, lg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 Protocolo de validación y corridas\n",
        "Split Train/Test (20% test). Para cada `p` y repetición, muestreo estratificado etiquetado dentro de Train; el resto se trata como no etiquetado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# División base Train/Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
        "\n",
        "ratios = [0.05, 0.10, 0.20, 0.40, 0.60, 0.80]\n",
        "repeats = 10\n",
        "taus = [0.6, 0.7, 0.8, 0.9]\n",
        "knns = [5, 10, 20]\n",
        "\n",
        "results = []\n",
        "\n",
        "for p in ratios:\n",
        "    for rep in range(repeats):\n",
        "        rs = RANDOM_STATE + rep + int(p*1000)\n",
        "        X_tr, y_tr = X_train.copy(), y_train.copy()\n",
        "        X_l, _, y_l, _ = train_test_split(X_tr, y_tr, train_size=p, stratify=y_tr, random_state=rs)\n",
        "        y_tr_semi = pd.Series(-1, index=X_tr.index)\n",
        "        y_tr_semi.loc[y_l.index] = y_l.values\n",
        "        # Baseline\n",
        "        yb_pred, yb_proba, _ = fit_predict_baseline(X_l, y_l, X_test)\n",
        "        b_f1, b_bal, _ = compute_metrics(y_test, yb_pred, classes_)\n",
        "        b_auc_macro = None\n",
        "        if yb_proba is not None:\n",
        "            _, b_auc_macro, _, _ = compute_roc_auc(y_test, yb_proba, classes_)\n",
        "        results.append({'p': p, 'rep': rep, 'method': 'baseline', 'param': None, 'f1_macro': b_f1, 'bal_acc': b_bal, 'auc_macro': b_auc_macro})\n",
        "        # Self-Training\n",
        "        for tau in taus:\n",
        "            ys_pred, ys_proba, _ = fit_predict_self_training(X_tr, y_tr_semi.values, X_test, threshold=tau)\n",
        "            s_f1, s_bal, _ = compute_metrics(y_test, ys_pred, classes_)\n",
        "            s_auc_macro = None\n",
        "            if ys_proba is not None:\n",
        "                _, s_auc_macro, _, _ = compute_roc_auc(y_test, ys_proba, classes_)\n",
        "            results.append({'p': p, 'rep': rep, 'method': 'self_training', 'param': {'tau': tau}, 'f1_macro': s_f1, 'bal_acc': s_bal, 'auc_macro': s_auc_macro, 'delta_f1': s_f1 - b_f1, 'delta_bal': s_bal - b_bal})\n",
        "        # Label Spreading/Propagation\n",
        "        for k in knns:\n",
        "            for meth in ['spreading', 'propagation']:\n",
        "                yl_pred, yl_proba, _ = fit_predict_label_graph(X_tr, y_tr_semi.values, X_test, method=meth, k=k)\n",
        "                l_f1, l_bal, _ = compute_metrics(y_test, yl_pred, classes_)\n",
        "                l_auc_macro = None\n",
        "                if yl_proba is not None:\n",
        "                    _, l_auc_macro, _, _ = compute_roc_auc(y_test, yl_proba, classes_)\n",
        "                results.append({'p': p, 'rep': rep, 'method': f'label_{meth}', 'param': {'k': k}, 'f1_macro': l_f1, 'bal_acc': l_bal, 'auc_macro': l_auc_macro, 'delta_f1': l_f1 - b_f1, 'delta_bal': l_bal - b_bal})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 Métricas de evaluación y comparación vs baseline\n",
        "- Macro F1, Balanced Accuracy, ROC-AUC (macro).\n",
        "- Ganancia vs baseline: ΔMacro-F1 y ΔBalanced-Acc.\n",
        "- Matriz de confusión por `p` (promedio sobre repeticiones)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen por método y p\n",
        "agg = results_df.groupby(['method','p']).agg(\n",
        "    f1_macro_mean=('f1_macro','mean'), f1_macro_std=('f1_macro','std'),\n",
        "    bal_acc_mean=('bal_acc','mean'), bal_acc_std=('bal_acc','std'),\n",
        "    auc_macro_mean=('auc_macro','mean')\n",
        ").reset_index()\n",
        "agg.sort_values(['method','p'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Curvas desempeño vs ratio_labeled p\n",
        "plt.figure(figsize=(10,6))\n",
        "for m in agg['method'].unique():\n",
        "    sub = agg[agg['method']==m]\n",
        "    plt.plot(sub['p'], sub['f1_macro_mean'], marker='o', label=f'{m} - F1 macro')\n",
        "plt.xlabel('ratio_labeled p')\n",
        "plt.ylabel('F1 macro (mean)')\n",
        "plt.title('Desempeño F1 macro vs p')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for m in agg['method'].unique():\n",
        "    sub = agg[agg['method']==m]\n",
        "    plt.plot(sub['p'], sub['bal_acc_mean'], marker='o', label=f'{m} - Balanced Acc')\n",
        "plt.xlabel('ratio_labeled p')\n",
        "plt.ylabel('Balanced Accuracy (mean)')\n",
        "plt.title('Desempeño Balanced Accuracy vs p')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Efecto de τ en Self-Training y de k en Label Graph\n",
        "st_sub = results_df[results_df['method']=='self_training']\n",
        "if not st_sub.empty:\n",
        "    st_sub = st_sub.copy()\n",
        "    st_sub['tau'] = st_sub['param'].apply(lambda d: d.get('tau') if isinstance(d, dict) else None)\n",
        "    plt.figure(figsize=(10,6))\n",
        "    for tau in sorted([t for t in st_sub['tau'].dropna().unique()]):\n",
        "        tmp = st_sub[st_sub['tau']==tau].groupby('p').agg(f1=('f1_macro','mean')).reset_index()\n",
        "        plt.plot(tmp['p'], tmp['f1'], marker='o', label=f'tau={tau}')\n",
        "    plt.title('Self-Training: F1 macro vs p por τ')\n",
        "    plt.xlabel('p')\n",
        "    plt.ylabel('F1 macro (mean)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "for meth in ['label_spreading','label_propagation']:\n",
        "    lg_sub = results_df[results_df['method']==meth]\n",
        "    if lg_sub.empty:\n",
        "        continue\n",
        "    lg_sub = lg_sub.copy()\n",
        "    lg_sub['k'] = lg_sub['param'].apply(lambda d: d.get('k') if isinstance(d, dict) else None)\n",
        "    plt.figure(figsize=(10,6))\n",
        "    for k in sorted([int(v) for v in lg_sub['k'].dropna().unique()]):\n",
        "        tmp = lg_sub[lg_sub['k']==k].groupby('p').agg(f1=('f1_macro','mean')).reset_index()\n",
        "        plt.plot(tmp['p'], tmp['f1'], marker='o', label=f'k={k}')\n",
        "    plt.title(f'{meth}: F1 macro vs p por k')\n",
        "    plt.xlabel('p')\n",
        "    plt.ylabel('F1 macro (mean)')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ganancia vs baseline (Δ) para cada método\n",
        "base = results_df[results_df['method']=='baseline'][['p','rep','f1_macro','bal_acc']].rename(columns={'f1_macro':'b_f1','bal_acc':'b_bal'})\n",
        "merged = results_df.merge(base, on=['p','rep'], how='left')\n",
        "merged['delta_f1_calc'] = merged['f1_macro'] - merged['b_f1']\n",
        "merged['delta_bal_calc'] = merged['bal_acc'] - merged['b_bal']\n",
        "gain = merged[merged['method']!='baseline'].groupby(['method','p']).agg(\n",
        "    dF1_mean=('delta_f1_calc','mean'), dF1_std=('delta_f1_calc','std'),\n",
        "    dBal_mean=('delta_bal_calc','mean'), dBal_std=('delta_bal_calc','std')\n",
        ").reset_index()\n",
        "gain.sort_values(['method','p'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3dc986c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test estadístico vs baseline (t-test pareado por p)\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "tests = []\n",
        "for p in ratios:\n",
        "    base_scores = results_df[(results_df['method']=='baseline') & (results_df['p']==p)]['f1_macro'].values\n",
        "    for meth in results_df['method'].unique():\n",
        "        if meth=='baseline':\n",
        "            continue\n",
        "        meth_scores = results_df[(results_df['method']==meth) & (results_df['p']==p)]['f1_macro'].values\n",
        "        if len(base_scores)==len(meth_scores) and len(base_scores)>1:\n",
        "            t, pval = ttest_rel(meth_scores, base_scores)\n",
        "            tests.append({'p': p, 'method': meth, 't_stat': t, 'p_value': pval})\n",
        "\n",
        "tests_df = pd.DataFrame(tests).sort_values(['method','p'])\n",
        "tests_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7cc48d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrices de confusión promedio por p y método (ejemplo de visualización)\n",
        "cm_summary = []\n",
        "for p in ratios:\n",
        "    for meth in results_df['method'].unique():\n",
        "        cms = []\n",
        "        for rep in range(repeats):\n",
        "            rs = RANDOM_STATE + rep + int(p*1000)\n",
        "            X_tr, y_tr = X_train.copy(), y_train.copy()\n",
        "            X_l, _, y_l, _ = train_test_split(X_tr, y_tr, train_size=p, stratify=y_tr, random_state=rs)\n",
        "            y_tr_semi = pd.Series(-1, index=X_tr.index)\n",
        "            y_tr_semi.loc[y_l.index] = y_l.values\n",
        "            if meth=='baseline':\n",
        "                y_pred, _, _ = fit_predict_baseline(X_l, y_l, X_test)\n",
        "            elif meth=='self_training':\n",
        "                tau = np.median(taus)\n",
        "                y_pred, _, _ = fit_predict_self_training(X_tr, y_tr_semi.values, X_test, threshold=float(tau))\n",
        "            elif meth in ['label_spreading','label_propagation']:\n",
        "                k = 10\n",
        "                y_pred, _, _ = fit_predict_label_graph(X_tr, y_tr_semi.values, X_test, method=meth.split('_')[1], k=int(k))\n",
        "            else:\n",
        "                continue\n",
        "            cm = confusion_matrix(y_test, y_pred, labels=classes_)\n",
        "            cms.append(cm)\n",
        "        if cms:\n",
        "            cm_mean = np.mean(cms, axis=0)\n",
        "            cm_summary.append({'p': p, 'method': meth, 'cm_mean': cm_mean})\n",
        "\n",
        "# Mostrar un ejemplo\n",
        "if cm_summary:\n",
        "    ex = cm_summary[0]\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(ex['cm_mean'], annot=True, fmt='.1f', xticklabels=classes_, yticklabels=classes_, cmap='Blues')\n",
        "    plt.title(f\"CM promedio - method={ex['method']} p={ex['p']}\")\n",
        "    plt.ylabel('True')\n",
        "    plt.xlabel('Pred')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROC y AUC (ejemplo de corrida)\n",
        "Se grafican curvas ROC macro para baseline y un método semisupervisado representativo (mejor F1 macro promedio)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "semi_methods = results_df[results_df['method']!='baseline'].groupby('method').agg(mean_f1=('f1_macro','mean')).sort_values('mean_f1', ascending=False)\n",
        "best_method = semi_methods.index[0] if len(semi_methods)>0 else None\n",
        "best_method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Curvas ROC en la última corrida del mejor método\n",
        "if best_method is not None:\n",
        "    last = results_df[results_df['method']==best_method].iloc[-1]\n",
        "    p = last['p']; rep = int(last['rep'])\n",
        "    rs = RANDOM_STATE + rep + int(p*1000)\n",
        "    X_tr, y_tr = X_train.copy(), y_train.copy()\n",
        "    X_l, _, y_l, _ = train_test_split(X_tr, y_tr, train_size=p, stratify=y_tr, random_state=rs)\n",
        "    y_tr_semi = pd.Series(-1, index=X_tr.index); y_tr_semi.loc[y_l.index] = y_l.values\n",
        "    _, b_proba, _ = fit_predict_baseline(X_l, y_l, X_test)\n",
        "    proba_semi = None\n",
        "    if best_method=='self_training':\n",
        "        tau = results_df[(results_df['method']=='self_training') & (results_df['p']==p)]['param'].iloc[-1]['tau']\n",
        "        _, proba_semi, _ = fit_predict_self_training(X_tr, y_tr_semi.values, X_test, threshold=tau)\n",
        "    elif best_method in ['label_spreading','label_propagation']:\n",
        "        k = results_df[(results_df['method']==best_method) & (results_df['p']==p)]['param'].iloc[-1]['k']\n",
        "        _, proba_semi, _ = fit_predict_label_graph(X_tr, y_tr_semi.values, X_test, method=best_method.split('_')[1], k=k)\n",
        "    if b_proba is not None:\n",
        "        _, b_auc_macro, fpr_b, tpr_b = compute_roc_auc(y_test, b_proba, classes_)\n",
        "        plt.figure(figsize=(7,6))\n",
        "        plt.plot([0,1],[0,1],'k--',alpha=0.3)\n",
        "        for c in classes_:\n",
        "            plt.plot(fpr_b[c], tpr_b[c], alpha=0.2)\n",
        "        plt.title(f'Baseline macro-AUC={b_auc_macro:.3f}')\n",
        "        plt.show()\n",
        "    if proba_semi is not None:\n",
        "        _, s_auc_macro, fpr_s, tpr_s = compute_roc_auc(y_test, proba_semi, classes_)\n",
        "        plt.figure(figsize=(7,6))\n",
        "        plt.plot([0,1],[0,1],'k--',alpha=0.3)\n",
        "        for c in classes_:\n",
        "            plt.plot(fpr_s[c], tpr_s[c], alpha=0.2)\n",
        "        plt.title(f'{best_method} macro-AUC={s_auc_macro:.3f}')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretabilidad: Importancia de variables (RF) y t-SNE coloreado por label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe_all = Pipeline(steps=[('prep', preprocess), ('clf', make_rf())])\n",
        "pipe_all.fit(X_train, y_train)\n",
        "rf = pipe_all.named_steps['clf']\n",
        "try:\n",
        "    importances = rf.feature_importances_\n",
        "    imp_df = pd.DataFrame({'feature': feature_cols[:len(importances)], 'importance': importances})\n",
        "    imp_df = imp_df.sort_values('importance', ascending=False).head(20)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.barplot(data=imp_df, x='importance', y='feature')\n",
        "    plt.title('Top-20 Importancias (RF)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print('No se pudieron calcular importancias:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 Análisis y reporte\n",
        "- Curvas desempeño vs `p` para cada método.\n",
        "- Test estadístico (t-test pareado vs baseline por `p`).\n",
        "- Efecto de `τ` y `k`.\n",
        "- Discusión de errores frecuentes por clase.\n",
        "\n",
        "### Notas sobre hiperparámetros y su efecto\n",
        "- `ratio_labeled (p)`: \n",
        "  - ↑p: más supervisión directa; mayor estabilidad.\n",
        "  - ↓p: mayor dependencia de semisupervisado; mayor sensibilidad a ruido.\n",
        "- `τ` en Self-Training: \n",
        "  - ↑τ: acepta menos pseudoetiquetas (más precisión, menos recall).\n",
        "  - ↓τ: acepta más pseudoetiquetas (más recall, riesgo de ruido).\n",
        "- `k` en Label Spreading/Propagation: \n",
        "  - ↑k: grafo denso, más suavizado; riesgo de sobre-propagación.\n",
        "  - ↓k: grafo esparcido; puede fragmentar clases.\n",
        "- `alpha` (Label Spreading): \n",
        "  - ↑alpha: más peso a vecinos.\n",
        "  - ↓alpha: más peso a etiquetas iniciales.\n",
        "- Random Forest: \n",
        "  - ↑n_estimators: menor varianza, mayor costo.\n",
        "  - ↓max_depth: más sesgo; ↑max_depth: menor sesgo y posible sobreajuste.\n",
        "- Preprocesamiento: imputación mediana + escalado + filtro de varianza.\n",
        "  - El escalado es crítico para k-NN y t-SNE."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
